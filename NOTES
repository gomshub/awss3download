NOTES:

python
import boto3

def sync_s3_subfolders(source_bucket, source_folder, destination_bucket, destination_folder):
    s3_client = boto3.client('s3')

    # Retrieve the list of objects in the source subfolder
    response = s3_client.list_objects_v2(Bucket=source_bucket, Prefix=source_folder)
    source_objects = response['Contents']

    # Iterate through the objects and copy them to the destination subfolder
    for obj in source_objects:
        key = obj['Key']
        destination_key = key.replace(source_folder, destination_folder, 1)  # Replace source folder with destination folder
        copy_source = {'Bucket': source_bucket, 'Key': key}
        s3_client.copy_object(CopySource=copy_source, Bucket=destination_bucket, Key=destination_key)

    print("Data synchronization completed.")

# Usage: Provide the names of the source and destination buckets, along with their subfolder paths
source_bucket_name = 'your-source-bucket'
source_folder_name = 'your-source-subfolder/'
destination_bucket_name = 'your-destination-bucket'
destination_folder_name = 'your-destination-subfolder/'

sync_s3_subfolders(source_bucket_name, source_folder_name, destination_bucket_name, destination_folder_name)

python
import os
import boto3

def upload_files_to_s3(bucket_name, directory_path):
    s3_client = boto3.client('s3')

    for root, dirs, files in os.walk(directory_path):
        for file in files:
            file_path = os.path.join(root, file)
            s3_key = os.path.relpath(file_path, directory_path)
            s3_client.upload_file(file_path, bucket_name, s3_key)

# Example usage
bucket_name = 'your-bucket-name'
directory_path = '/path/to/your/directory'

upload_files_to_s3(bucket_name, directory_path)

python
import os
import datetime
import boto3

def create_subfolder_with_date_format(bucket_name, file_path):
    s3_client = boto3.client('s3')
    
    # Get the file's modification timestamp
    file_timestamp = os.path.getmtime(file_path)
    
    # Convert the timestamp to datetime object
    file_datetime = datetime.datetime.fromtimestamp(file_timestamp)
    
    # Generate the desired date format
    date_format = file_datetime.strftime('%Y-%m-%d')
    
    # Create the subfolder using the date format
    subfolder_path = f'{date_format}/'
    s3_client.put_object(Bucket=bucket_name, Key=subfolder_path)
    
# Example usage
bucket_name = 'your-bucket-name'
file_path = '/path/to/your/file.txt'

create_subfolder_with_date_format(bucket_name, file_path)


python
import pyarrow.parquet as pq

# Define the path to the input Parquet file
input_file = 'input.parquet'

# Define the path to the output Parquet file
output_file = 'output.parquet'

# Define the value you want to lookup
lookup_value = 'your_lookup_value'

# Read the input Parquet file
table = pq.read_table(input_file)

# Convert the Parquet table to a Pandas DataFrame
df = table.to_pandas()

# Filter the DataFrame based on the lookup value
matched_rows = df[df['column_name'] == lookup_value]

# Convert the filtered DataFrame back to a PyArrow Table
output_table = pa.Table.from_pandas(matched_rows)

# Write the output table to the output Parquet file
pq.write_table(output_table, output_file)










